{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzyuzzz/123/blob/master/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, Compose, Resize\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "ANK6FYZ37aMl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.WIDERFace(\n",
        "    root='data',\n",
        "    split='train',\n",
        "    transform=ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "testing_data = datasets.WIDERFace(\n",
        "    root='data',\n",
        "    split='test',\n",
        "    transform=ToTensor(),\n",
        "    download=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHyS2Qrd8uVz",
        "outputId": "5188ffc5-7313-492f-d271-d7d18547b37e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps5-YaX-ZhkR",
        "outputId": "67c0879e-e467-4aa0-8ebf-0f123fbae1f8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0275, 0.0392, 0.0627,  ..., 0.0471, 0.0471, 0.0471],\n",
              "          [0.0353, 0.0353, 0.0392,  ..., 0.0588, 0.0627, 0.0667],\n",
              "          [0.0706, 0.0549, 0.0431,  ..., 0.0588, 0.0627, 0.0667],\n",
              "          ...,\n",
              "          [0.8667, 0.8118, 0.8510,  ..., 0.6667, 0.6941, 0.5804],\n",
              "          [0.7961, 0.8471, 0.8627,  ..., 0.6353, 0.6745, 0.6000],\n",
              "          [0.7843, 0.8824, 0.8667,  ..., 0.6118, 0.6902, 0.6353]],\n",
              " \n",
              "         [[0.0549, 0.0667, 0.0902,  ..., 0.0392, 0.0392, 0.0392],\n",
              "          [0.0627, 0.0627, 0.0667,  ..., 0.0510, 0.0549, 0.0588],\n",
              "          [0.0980, 0.0824, 0.0706,  ..., 0.0510, 0.0549, 0.0588],\n",
              "          ...,\n",
              "          [1.0000, 0.9608, 0.9922,  ..., 0.5569, 0.5804, 0.4627],\n",
              "          [0.9490, 1.0000, 1.0000,  ..., 0.5176, 0.5569, 0.4824],\n",
              "          [0.9451, 1.0000, 1.0000,  ..., 0.4902, 0.5686, 0.5137]],\n",
              " \n",
              "         [[0.0941, 0.1059, 0.1294,  ..., 0.0510, 0.0510, 0.0510],\n",
              "          [0.1020, 0.1020, 0.1059,  ..., 0.0627, 0.0667, 0.0706],\n",
              "          [0.1373, 0.1216, 0.1098,  ..., 0.0627, 0.0667, 0.0706],\n",
              "          ...,\n",
              "          [1.0000, 0.9647, 0.9922,  ..., 0.5529, 0.5882, 0.4706],\n",
              "          [0.9686, 1.0000, 1.0000,  ..., 0.5098, 0.5569, 0.4824],\n",
              "          [0.9608, 1.0000, 1.0000,  ..., 0.4784, 0.5608, 0.5059]]]),\n",
              " None)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "MbYG5ligbkFD"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for X, y in train_dataloader:\n",
        "  i = i + 1\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(\"bbox\", y['bbox'])\n",
        "  if i > 10:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNuyREBnb5B3",
        "outputId": "6a0068ec-5e14-458f-99e9-29b66950bc05"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 724, 1024])\n",
            "bbox tensor([[[276, 218, 102, 134]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 701, 1024])\n",
            "bbox tensor([[[138, 224, 162, 214],\n",
            "         [252, 166, 220, 224]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 640, 1024])\n",
            "bbox tensor([[[ 68,  14,  52,  68],\n",
            "         [794,  40,  54,  64]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 681, 1024])\n",
            "bbox tensor([[[248,  44,  78, 140],\n",
            "         [366, 220,  60,  80],\n",
            "         [542, 156,  66,  90],\n",
            "         [690, 308,  60,  82],\n",
            "         [810, 330,  58,  88]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 672, 1024])\n",
            "bbox tensor([[[883, 138,  40,  32],\n",
            "         [753, 141,  54,  41],\n",
            "         [558, 124,  63,  51],\n",
            "         [652, 145,  36,  31],\n",
            "         [299, 137,  46,  42],\n",
            "         [112, 122,  40,  37]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 1541, 1024])\n",
            "bbox tensor([[[358, 343, 151, 202],\n",
            "         [638, 907, 181, 199]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 472, 1024])\n",
            "bbox tensor([[[155,  76,  10,  14],\n",
            "         [187,  76,  11,  16],\n",
            "         [218,  82,  11,  14],\n",
            "         [252,  81,  11,  14],\n",
            "         [284,  78,  12,  15],\n",
            "         [282, 109,  10,  14],\n",
            "         [245, 110,  12,  16],\n",
            "         [211, 111,  12,  15],\n",
            "         [178, 109,  12,  17],\n",
            "         [144, 110,  11,  14],\n",
            "         [308, 140,  11,  15],\n",
            "         [276, 142,  11,  14],\n",
            "         [239, 139,  11,  15],\n",
            "         [208, 141,   9,  13],\n",
            "         [175, 140,   9,  14],\n",
            "         [136, 141,  11,  15],\n",
            "         [131, 169,  12,  16],\n",
            "         [169, 172,  10,  15],\n",
            "         [201, 171,  11,  17],\n",
            "         [237, 172,  10,  15],\n",
            "         [271, 173,  11,  16],\n",
            "         [307, 171,  11,  16],\n",
            "         [320,  79,  12,  16],\n",
            "         [360,  76,  12,  16],\n",
            "         [397,  78,  12,  16],\n",
            "         [434,  77,  11,  16],\n",
            "         [430, 108,  11,  16],\n",
            "         [393, 109,  11,  15],\n",
            "         [354, 109,  10,  16],\n",
            "         [317, 109,  11,  15],\n",
            "         [348, 138,  11,  16],\n",
            "         [387, 137,  13,  15],\n",
            "         [424, 137,  11,  16],\n",
            "         [460, 138,  11,  15],\n",
            "         [460, 171,  11,  15],\n",
            "         [423, 170,  12,  15],\n",
            "         [381, 169,  12,  17],\n",
            "         [343, 168,  11,  16],\n",
            "         [472,  76,  12,  16],\n",
            "         [511,  74,  10,  14],\n",
            "         [549,  75,  10,  15],\n",
            "         [586,  74,  11,  16],\n",
            "         [625,  71,  12,  16],\n",
            "         [620, 103,  12,  18],\n",
            "         [584, 107,  11,  15],\n",
            "         [547, 103,  10,  15],\n",
            "         [505, 103,  10,  16],\n",
            "         [468, 106,  11,  15],\n",
            "         [501, 139,  10,  15],\n",
            "         [540, 135,  12,  16],\n",
            "         [580, 135,  11,  16],\n",
            "         [619, 129,  11,  18],\n",
            "         [613, 166,  11,  16],\n",
            "         [577, 166,  11,  17],\n",
            "         [538, 168,  12,  16],\n",
            "         [497, 168,  11,  18],\n",
            "         [662,  72,  12,  15],\n",
            "         [700,  69,  11,  16],\n",
            "         [741,  68,  12,  16],\n",
            "         [783,  66,  12,  16],\n",
            "         [822,  65,  13,  17],\n",
            "         [862,  61,  12,  17],\n",
            "         [859,  94,  13,  18],\n",
            "         [820,  98,  11,  15],\n",
            "         [781,  99,  12,  16],\n",
            "         [742, 101,  12,  15],\n",
            "         [699, 101,  12,  16],\n",
            "         [659, 102,  12,  15],\n",
            "         [819, 131,  11,  16],\n",
            "         [780, 129,  13,  16],\n",
            "         [742, 132,  11,  16],\n",
            "         [694, 133,  13,  17],\n",
            "         [656, 134,  12,  17],\n",
            "         [652, 166,  12,  15],\n",
            "         [694, 169,  10,  15],\n",
            "         [738, 165,  12,  17],\n",
            "         [779, 165,  13,  17],\n",
            "         [819, 163,  11,  15],\n",
            "         [820, 198,  11,  17],\n",
            "         [777, 199,  12,  16],\n",
            "         [734, 200,  12,  17],\n",
            "         [694, 200,  12,  16],\n",
            "         [649, 200,  13,  16],\n",
            "         [899,  57,  12,  14],\n",
            "         [900,  96,  12,  14],\n",
            "         [904, 128,  13,  16],\n",
            "         [860, 134,  12,  15],\n",
            "         [859, 163,  12,  15],\n",
            "         [910, 163,  11,  16],\n",
            "         [860, 200,  13,  15],\n",
            "         [907, 196,  12,  16],\n",
            "         [971, 259,  14,  18],\n",
            "         [956, 245,  13,  17],\n",
            "         [942, 267,  13,  16],\n",
            "         [905, 232,  12,  16],\n",
            "         [911, 271,  12,  16],\n",
            "         [886, 278,  12,  18],\n",
            "         [865, 268,  12,  17],\n",
            "         [871, 307,  13,  15],\n",
            "         [842, 281,  14,  18],\n",
            "         [818, 310,  15,  17],\n",
            "         [818, 272,  13,  16],\n",
            "         [862, 232,  12,  16],\n",
            "         [820, 232,  13,  17],\n",
            "         [899, 356,  13,  15],\n",
            "         [812, 357,  13,  15],\n",
            "         [793, 331,  14,  16],\n",
            "         [757, 304,  13,  16],\n",
            "         [716, 350,  14,  18],\n",
            "         [705, 306,  14,  18],\n",
            "         [773, 270,  13,  18],\n",
            "         [775, 231,  14,  19],\n",
            "         [729, 275,  13,  17],\n",
            "         [689, 273,  12,  16],\n",
            "         [733, 236,  13,  16],\n",
            "         [688, 236,  14,  15],\n",
            "         [ 55, 261,  13,  16],\n",
            "         [ 73, 271,  11,  15],\n",
            "         [ 97, 273,  10,  13],\n",
            "         [109, 279,  13,  15],\n",
            "         [137, 275,  12,  14],\n",
            "         [110, 236,  12,  15],\n",
            "         [146, 240,  11,  14],\n",
            "         [181, 236,  11,  14],\n",
            "         [217, 237,  10,  14],\n",
            "         [257, 238,  11,  15],\n",
            "         [251, 272,  10,  14],\n",
            "         [206, 272,  11,  15],\n",
            "         [170, 273,  11,  15],\n",
            "         [229, 307,  12,  15],\n",
            "         [173, 308,  13,  14],\n",
            "         [184, 335,  13,  17],\n",
            "         [142, 322,  14,  16],\n",
            "         [125, 305,  12,  15],\n",
            "         [ 77, 299,  14,  17],\n",
            "         [ 97, 344,  14,  16],\n",
            "         [ 43, 339,  15,  17],\n",
            "         [258, 304,  13,  14],\n",
            "         [285, 324,  13,  13],\n",
            "         [315, 352,  13,  16],\n",
            "         [377, 330,  15,  16],\n",
            "         [344, 309,  12,  17],\n",
            "         [328, 307,  14,  16],\n",
            "         [450, 328,  11,  16],\n",
            "         [415, 309,  12,  15],\n",
            "         [447, 276,  11,  16],\n",
            "         [407, 274,  10,  14],\n",
            "         [367, 270,  12,  14],\n",
            "         [328, 275,  11,  14],\n",
            "         [287, 274,  11,  16],\n",
            "         [634, 326,  12,  15],\n",
            "         [669, 310,  13,  14],\n",
            "         [587, 356,  13,  14],\n",
            "         [571, 313,  13,  15],\n",
            "         [599, 310,  12,  15],\n",
            "         [647, 275,  12,  15],\n",
            "         [605, 272,  11,  14],\n",
            "         [564, 275,  10,  15],\n",
            "         [528, 278,   9,  15],\n",
            "         [488, 280,  11,  12],\n",
            "         [523, 332,  12,  16],\n",
            "         [506, 318,  12,  15],\n",
            "         [478, 332,  12,  15],\n",
            "         [469, 307,  12,  16],\n",
            "         [127, 203,  10,  13],\n",
            "         [160, 203,  12,  14],\n",
            "         [195, 203,  10,  14],\n",
            "         [230, 206,  10,  13],\n",
            "         [265, 204,  11,  14],\n",
            "         [294, 235,  10,  14],\n",
            "         [333, 238,  10,  13],\n",
            "         [373, 237,   9,  14],\n",
            "         [378, 203,  10,  16],\n",
            "         [340, 203,  11,  14],\n",
            "         [301, 203,  10,  15],\n",
            "         [645, 237,  12,  14],\n",
            "         [607, 232,  11,  15],\n",
            "         [608, 200,  12,  16],\n",
            "         [570, 202,  12,  14],\n",
            "         [567, 234,  11,  16],\n",
            "         [526, 238,  11,  15],\n",
            "         [532, 201,  11,  15],\n",
            "         [492, 203,  12,  17],\n",
            "         [488, 235,  11,  16],\n",
            "         [451, 234,  11,  14],\n",
            "         [456, 201,  11,  15],\n",
            "         [418, 202,  12,  18],\n",
            "         [413, 236,  12,  16]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 577, 1024])\n",
            "bbox tensor([[[108, 144,  78, 120],\n",
            "         [264,  94,  80, 110],\n",
            "         [456,  38,  82, 112],\n",
            "         [642,  46,  74, 104],\n",
            "         [828, 110,  80, 100]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 1345, 1024])\n",
            "bbox tensor([[[428, 226,  74, 108],\n",
            "         [494, 121,  81, 116]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 768, 1024])\n",
            "bbox tensor([[[105, 377,  20,  20],\n",
            "         [173, 388,  21,  23],\n",
            "         [137, 318,  19,  24],\n",
            "         [164, 298,  21,  22],\n",
            "         [178, 338,  22,  26],\n",
            "         [225, 308,  21,  27],\n",
            "         [255, 290,  23,  24],\n",
            "         [283, 337,  19,  22],\n",
            "         [300, 302,  19,  21],\n",
            "         [337, 268,  19,  22],\n",
            "         [352, 295,  18,  22],\n",
            "         [377, 316,  16,  18],\n",
            "         [417, 306,  16,  19],\n",
            "         [407, 274,  19,  21],\n",
            "         [444, 288,  19,  21],\n",
            "         [470, 313,  17,  20],\n",
            "         [517, 315,  16,  20],\n",
            "         [561, 300,  16,  18],\n",
            "         [521, 277,  19,  22],\n",
            "         [524, 218,  15,  19],\n",
            "         [571, 392,  19,  21],\n",
            "         [508, 458,  23,  26],\n",
            "         [433, 455,  25,  25],\n",
            "         [357, 485,  21,  23],\n",
            "         [281, 512,  22,  26],\n",
            "         [308, 399,  24,  27],\n",
            "         [330, 316,  18,  21],\n",
            "         [614, 280,  16,  17],\n",
            "         [650, 306,  16,  19],\n",
            "         [667, 253,  21,  22],\n",
            "         [686, 279,  17,  12],\n",
            "         [723, 281,  17,  22],\n",
            "         [738, 249,  19,  24],\n",
            "         [785, 268,  17,  19],\n",
            "         [827, 252,  21,  25],\n",
            "         [887, 245,  26,  27],\n",
            "         [833, 416,  17,  18],\n",
            "         [795, 389,  23,  24],\n",
            "         [703, 373,  25,  30]]])\n",
            "Shape of X [N, C, H, W]: torch.Size([1, 3, 640, 1024])\n",
            "bbox tensor([[[158, 154,  72, 104],\n",
            "         [820, 112,  72, 112]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLO_V1(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 7, 2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d((2, 2), 2)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 192, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d((2, 2), 2)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(192, 128, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(128, 256, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 256, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d((2, 2), 2)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 256, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 256, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 256, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 512, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 1024, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d((2, 2), 2)\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(1024, 512, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 1024, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(1024, 512, (1, 1)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 1024, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(1024, 1024, (3, 3), 2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "        )\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(1024, 1024, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(1024, 1024, (3, 3)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "        )\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(1024, 4096, (7, 7)),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(4096, 245, (1, 1)),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        print(x.shape)\n",
        "        x = self.layer6(x)\n",
        "        x = self.layer7(x)\n",
        "        return torch.reshape(x, (7, 7, 5))\n"
      ],
      "metadata": {
        "id": "fTpxZOIr8ldc"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "lambda_coord = 5\n",
        "lambda_noobj = .5"
      ],
      "metadata": {
        "id": "GtsnPVJl8uXE"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def squareDiff(x:tuple, y:tuple):\n",
        "    t = x - y\n",
        "    return t[0] ** 2 + t[1] ** 2\n",
        "\n",
        "def objInCell(box, truth_box):\n",
        "    center_x = truth_box[0] + truth_box[2] / 2\n",
        "    center_y = truth_box[1] + truth_box[3] / 2\n",
        "    return box[0] <= center_x and box[0] + box[2] >= center_x \\\n",
        "            and box[1] <= center_y and box[1] + box[3] >= center_y"
      ],
      "metadata": {
        "id": "C7u9c2d_8xEb"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = 7\n",
        "\n",
        "def Loss(X, bbox):\n",
        "    loss_coord = 0\n",
        "    loss_noobj = 0\n",
        "    loss_0 = 0\n",
        "    for x in X:\n",
        "        for i in x.shape[0]:\n",
        "            for j in x.shape[1]:\n",
        "                center_x = x[i, j][0] - x[i, j][2] / 2\n",
        "                center_y = x[i, j][1] - x[i, j][3] / 2\n",
        "                for y in bbox:\n",
        "                    if objInCell((center_x, \n",
        "                                center_y,\n",
        "                                x[i, j][2],x[i, j][3]\n",
        "                                ), y):\n",
        "                        loss_coord = loss_coord + squareDiff((center_x, center_y), (y[0], y[1]))\n",
        "                        loss_coord = loss_coord + squareDiff((math.sqrt(x[i, j][2]),\n",
        "                                                            math.sqrt(x[i, j][3])), \n",
        "                                                            (math.sqrt(y[2]),\n",
        "                                                            math.sqrt(y[3])))\n",
        "                        loss_0 = loss_0 + (1 - x[i, j, 4]) ** 2\n",
        "                    else:\n",
        "                        loss_noobj = loss_noobj + x[i, j, 4] ** 2\n",
        "\n",
        "    return lambda_coord * loss_coord + lambda_noobj * loss_noobj + loss_0\n",
        "\n"
      ],
      "metadata": {
        "id": "xWziAZ1J82iM"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "lleICnR585tb",
        "outputId": "40f5564a-f85f-4610-c15e-307f27cf9c58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eeq9s6O19KzM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO_V1().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "J0ME4Ev19C27",
        "outputId": "d20ff816-aa20-4e6f-f345-d4eff121f77f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO_V1(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.1)\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.1)\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.1)\n",
            "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.1)\n",
            "    (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.1)\n",
            "    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.1)\n",
            "    (8): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.1)\n",
            "    (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.1)\n",
            "    (4): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.1)\n",
            "    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.1)\n",
            "    (8): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (9): LeakyReLU(negative_slope=0.1)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (11): LeakyReLU(negative_slope=0.1)\n",
            "    (12): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (13): LeakyReLU(negative_slope=0.1)\n",
            "    (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (15): LeakyReLU(negative_slope=0.1)\n",
            "    (16): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (17): LeakyReLU(negative_slope=0.1)\n",
            "    (18): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (19): LeakyReLU(negative_slope=0.1)\n",
            "    (20): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer5): Sequential(\n",
            "    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.1)\n",
            "    (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.1)\n",
            "    (4): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (5): LeakyReLU(negative_slope=0.1)\n",
            "    (6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (7): LeakyReLU(negative_slope=0.1)\n",
            "    (8): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (9): LeakyReLU(negative_slope=0.1)\n",
            "  )\n",
            "  (layer6): Sequential(\n",
            "    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.1)\n",
            "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.1)\n",
            "  )\n",
            "  (layer7): Sequential(\n",
            "    (0): Conv2d(1024, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.1)\n",
            "    (2): Conv2d(4096, 245, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (3): LeakyReLU(negative_slope=0.1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch, (X, y) in enumerate(train_dataloader):\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "id": "fCxk7_Ke9_Ys",
        "outputId": "444447fc-937e-4b1e-fb01-ad017ece0ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bbox': tensor([[[244, 254,  71, 100],\n",
            "         [366, 255,  66,  85],\n",
            "         [442, 234,  74, 102],\n",
            "         [867, 427,  20,  21],\n",
            "         [779, 375,  18,  23],\n",
            "         [678, 358,  13,  18],\n",
            "         [610, 356,  15,  21],\n",
            "         [592, 347,  11,  14],\n",
            "         [957, 293,   9,  12],\n",
            "         [883, 294,   8,   9]]]), 'blur': tensor([[1, 1, 1, 2, 1, 2, 1, 2, 2, 2]]), 'expression': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'illumination': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'occlusion': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'pose': tensor([[0, 0, 0, 1, 1, 1, 1, 1, 0, 0]]), 'invalid': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "RgI7S4H-9T7b"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        y = y['bbox']\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        print(X.shape)\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "uuk-_k0L9YPL"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, Loss, optimizer)\n",
        "    # test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "6PnWeuV-9q-D",
        "outputId": "e02a01af-c1d8-4a4d-e4bd-0980aeb3f1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "torch.Size([1, 3, 663, 1024])\n",
            "torch.Size([1, 1024, 4, 10])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-8b28d3808fed>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# test(test_dataloader, model, loss_fn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-4b3a78839860>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Compute prediction error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-947b0fcd34b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2 x 8). Kernel size: (3 x 3). Kernel size can't be greater than actual input size"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "欢迎使用 Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}